---
title: "Analysis of ClusterChanges technique applied to Java open source projects at GitHub"
output: pdf_document
---
# Introduction

Considering the promising results of the recently devised ClusterChanges (CC) technique published by Barnett et al., we would like to better understand how widely applicable the technique is. To this end, we intend to analyze how ClusterChanges performs in a different context, namely open source software projects written by different organizations. 

In this initial study, we aimed to replicate the original quantitative study as closely as possible while using a an open source software context. Therefore, we applied the ClusterChanges technique to a sample of 1000 pull requests from the most popular Java OSS projects hosted at GitHub. 

We chose to use pull requests because we believe they closely mirror the changesets used in the original CC study. That is, both are sets of pairs of changed files (before-file and after-file) that were submitted to be reviewed by other developers. As for using the most popular OSS projects, we hypothesized that they would have large numbers of pull requests to analyze. We chose GitHub because, at the time of writing, it is the largest code hoster in the world with about 21.3M repositories and a large amount of those are OSS projects. Regarding Java, aside from being a popular language for OSS projects, it allows us to verify if ClusterChanges is applicable to other programming languages.

We have implemented the ClusterChanges technique for Java projects and refer to this implementation as *ccjava* in this document. As the Roslyn compiler only works with C# code, we used the Eclipse Compiler for Java (ECJ) for parsing Java code in order to identify def-use, use-use and same enclosing methods relationships between diff-regions. We chose ECJ because it's a mature, open and incremental compiler whose main goal is analyzing partial programs that may not be fully compilable. The Eclipse IDE uses ECJ for performing real-time static analysis while the developers are editing the source code.


# Goal

* Analyze the effectiveness of ClusterChanges in the context of open source projects;
* Compare these results with the original study results, which were obtained in a different context.

# Data collection

In this section, we describe how we obtained the data used in this analysis. The dataset used is available at: <https://github.com/victorclf/ccjava-analysis>

## Software project sample selection

We chose 10 software projects from GitHub in the following way:

1. In the GitHub web page, we asked for the list of open source Java projects in descending order of **stars** (search string: *stars:>1 language:java*). We hypothesized that the projects with the most stars are the most popular and would have the most pull requests.
2. Then we manually analyzed each software project in the list (until we had 10 projects) and selected it for the study if:
  + It used GitHub's pull request system;
  + It was not a mirror of a repository maintained somewhere else. When this is case, the GitHub's pull request system  is not being used by the project;
  + It had at least 300 pull requests which contained Java source code;
  + It was targeted at the JVM (i.e. Android exclusive projects were not considered);

## Pull request

A pull request consists of the created/modified files (after-files) and their corresponding diff files.

## Pull request sampling

For each software project:

1. Sampled 300 pull requests at random that matched the following criteria:
  + Had at least one Java source code after-file (deleted files are ignored)
2. Ran ccjava on these 300 pull requests;
3. Of these 300 pull requests, sampled 100 pull requests at random that matched the following criteria:
  + Was analyzed by ccjava without errors or warnings (see Limitations section at the end)

# Dataset description

The dataset is composed of the files below which were obtained after running ccjava on 1000 changesets:

* allDefs.csv (Project name, Pull request ID, Definition ID, Source file, Character span, Name, Is type definition?, Is method definition?, Is inside a diff-region?)
* allUses.csv (Project name, Pull request ID, Use ID, Source file, Character span, Name, Associated definition)
* allDiffs.csv (Project name, Pull request ID, Diff-region ID, Source file, Line span, Character span)
* allDiffRelations.csv (Project name, Pull request ID, Relation ID, Relation type, Diff-region 1, Diff-region 2)
* allPartitions.csv (Project name, Pull request ID, Partition ID, Is partition trivial?, A diff region that is part of the partition, Method enclosing the diff-region)
* allSummary.csv (Project name, Pull request ID, Number of source files, Number of definitions, Number of uses, Number of diff-regions, Number of partitions, Number of non-trivial partitions, Number of trivial partitions)


# Analysis

```{r, echo=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(grid)
library(scales)
summ <- read.csv("data/allSummary.csv")
partitions <- read.csv("data/allPartitions.csv")

pullRequests <- select(summ, projectName, pullRequestId)

trivialPartitions <- select(summ, trivialPartitions)

nonTrivialPartitions <- select(summ, nonTrivialPartitions)
```

## Pull Requests

### Boxplots of Change Sizes

```{r, echo=FALSE, warning=FALSE}
filesChanged <- select(summ, projectName, pullRequestId, filesChanged = sourceFiles)
enclosingMethods <- partitions %>%
  select(projectName, pullRequestId, enclosingMethodDefId) %>%
  distinct() %>%
  filter(enclosingMethodDefId != "null")
methodsChanged <-left_join(pullRequests, enclosingMethods, by=c("projectName", "pullRequestId")) %>%
  group_by(projectName, pullRequestId) %>%
  summarise(methodsChanged = sum(!is.na(enclosingMethodDefId)))
diffRegions <- select(summ, projectName, pullRequestId, diffRegions = diffs)

filesChangedBoxplot = ggplot(filesChanged, aes(x="", y=filesChanged)) +
  geom_boxplot() +
  coord_cartesian(ylim=c(0,30)) +
  scale_y_continuous(breaks=seq(0, 30, by=2)) +
  xlab("Files Changed") +
  ylab("")
methodsChangedBoxplot = ggplot(methodsChanged, aes(x="", y=methodsChanged)) +
  geom_boxplot() +
  coord_cartesian(ylim=c(0,40)) +
  scale_y_continuous(breaks=seq(0, 40, by=2)) +
  xlab("Methods Changed") +
  ylab("")
diffRegionsBoxplot = ggplot(diffRegions, aes(x="", y=diffRegions)) +
  geom_boxplot() +
  coord_cartesian(ylim=c(0, 100)) +
  scale_y_continuous(breaks=seq(0, 100, by=5)) +
  xlab("Diff Regions") +
  ylab("")
pushViewport(viewport(layout = grid.layout(1, 3)))
print(filesChangedBoxplot, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
print(methodsChangedBoxplot, vp = viewport(layout.pos.row = 1, layout.pos.col = 2))
print(diffRegionsBoxplot, vp = viewport(layout.pos.row = 1, layout.pos.col = 3))
```

### Files Changed

```{r, echo=FALSE, warning=FALSE}
ggplot(filesChanged, aes(x=filesChanged)) + geom_histogram(breaks=seq(0, 30, by=1), col="black", fill="lightblue") + xlab("Files Changed")
```

Quantiles

```{r, echo=FALSE, warning=FALSE, comment=""}
quantile(x=filesChanged$filesChanged, probs=seq(0.05, 1, 0.05))
filesChangedECDF = ecdf(filesChanged$filesChanged)
```

The histogram of Java source code files that were edited in each pull request indicate that changes in pull requests tend to be focused on a very small amount of files. In this sample, `r percent(filesChangedECDF(2))` of the pull requests affected at most 2 files and `r percent(filesChangedECDF(4))` of the pull requests affected at most 4 files.

### Methods Changed

```{r, echo=FALSE, warning=FALSE}
ggplot(methodsChanged, aes(x=methodsChanged)) + geom_histogram(breaks=seq(0, 50, by=1), col="black", fill="lightblue") + xlab("Methods Changed")
```

Quantiles

```{r, echo=FALSE, warning=FALSE, comment=""}
quantile(x=methodsChanged$methodsChanged, probs=seq(0.05, 1, 0.05))
```

### Diff Regions

```{r, echo=FALSE, warning=FALSE}
ggplot(diffRegions, aes(x=diffRegions)) + geom_histogram(breaks=seq(0, 100, by=1), col="black", fill="lightblue") + xlab("Diff Regions")
```

Quantiles

```{r, echo=FALSE, warning=FALSE, comment=""}
quantile(x=diffRegions$diffRegions, probs=seq(0.05, 1, 0.05))
```

## Partitions

### Histogram of trivial partitions

```{r, echo=FALSE}
ggplot(data=summ, aes(trivialPartitions)) + geom_histogram(breaks=seq(0, 20, by=1), col="black", fill="lightblue")
summary(summ$trivialPartitions)
```

### Histogram of non-trivial partitions

```{r, echo=FALSE}
ggplot(data=nonTrivialPartitions, aes(nonTrivialPartitions)) + geom_histogram(breaks=seq(0, 10, by=1), col="black", fill="lightblue")
summary(nonTrivialPartitions$nonTrivialPartitions)
```


# Main findings

TODO

# Limitations
As of this writing, some changesets aren't being fully analyzed by our tool. This seem to be caused by limitations in ECJ. For instance, we have observed that ECJ is not detecting the use of a field when this use is inside a lambda function. As this may result in missing relationships and seem to be implementation issues unrelated to ClusterChanges, we have excluded such changesets from the dataset for now.

# Future work

* Is there a relationship between the number of non-trivial/trivial partitions and whether the pull request was accepted?